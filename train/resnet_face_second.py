import glob

import torch
import torch.nn as nn
import torch.optim as optim
from torch import autocast
from torch.cuda.amp import GradScaler
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, Subset
from sklearn.model_selection import train_test_split
import os
from tqdm import tqdm
import matplotlib.pyplot as plt

# ç”¨ç¬¬äºŒå—æ˜¾å¡è®­ç»ƒ
os.environ["CUDA_VISIBLE_DEVICES"] = "1"
# --- 1. é…ç½®å‚æ•° ---
data_dir = r"D:\dataset\frame_picture\classified_frames_face_101"  # ä½ ä¹‹å‰åˆ†ç±»å¥½çš„æ ¹ç›®å½•
batch_size = 256
num_epochs = 100
learning_rate = 0.0001
num_classes = 5  # ä½, ç¨ä½, ä¸­æ€§, ç¨é«˜, é«˜
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- 2. æ•°æ®å¢å¼ºä¸é¢„å¤„ç† ---
# ResNet æ ‡å‡†è¾“å…¥æ˜¯ 224x224
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(0.2, 0.2, 0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

# --- 3. åŠ è½½æ•°æ®é›†å¹¶åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›† ---
# è‡ªå®šä¹‰æ•°æ®é›†ç±»ï¼Œæ”¯æŒæŒ‰æ—¶é—´åŒºé—´åˆ†ç»„é€‰æ‹©ä¸€å¸§
class TimeIntervalDataset(torch.utils.data.Dataset):
    def __init__(self, data_dir):
        self.data_dir = data_dir
        self.samples = []
        self.targets = []
        
        # éå†æ‰€æœ‰ç±»åˆ«æ–‡ä»¶å¤¹
        class_to_idx = {}
        for i, class_name in enumerate(sorted(os.listdir(data_dir))):
            class_to_idx[class_name] = i
            class_path = os.path.join(data_dir, class_name)
            if not os.path.isdir(class_path):
                continue
            
            # æŒ‰æ—¶é—´åŒºé—´åˆ†ç»„æ–‡ä»¶
            interval_groups = {}
            for filename in os.listdir(class_path):
                if filename.endswith('.jpg'):
                    # æå–æ—¶é—´åŒºé—´ï¼šframe_000000_192.168.0.101_01_20231229153000_20231229154000.jpg
                    parts = filename.split('_')
                    if len(parts) >= 5:
                        interval = f"{parts[-2]}_{parts[-1].split('.')[0]}"
                        if interval not in interval_groups:
                            interval_groups[interval] = []
                        interval_groups[interval].append(filename)
            
            # æ¯ä¸ªæ—¶é—´åŒºé—´æ¯åå¼ å›¾ç‰‡é€‰å–ä¸€å¼ 
            for interval, files in interval_groups.items():
                if files:
                    # æŒ‰å¸§å·æ’åº
                    files.sort()
                    # æ¯åå¼ é€‰å–ä¸€å¼ ï¼ˆå‡åŒ€é‡‡æ ·ï¼‰
                    step = 10
                    for i in range(0, len(files), step):
                        # å–æ¯åå¼ çš„ä¸­é—´ä½ç½®ï¼ˆç¬¬5å¼ ï¼Œç´¢å¼•ä¸º4ï¼‰
                        selected_idx = min(i + 4, len(files) - 1)
                        selected_file = files[selected_idx]

                        img_path = os.path.join(class_path, selected_file)
                        self.samples.append(img_path)
                        self.targets.append(class_to_idx[class_name])
    
    def __len__(self):
        return len(self.samples)

# åˆ›å»ºæ•°æ®é›†å®ä¾‹

full_dataset = TimeIntervalDataset(data_dir)

# è·å–ç´¢å¼•è¿›è¡Œåˆ’åˆ† (80% è®­ç»ƒ, 20% éªŒè¯)
train_idx, val_idx = train_test_split(
    list(range(len(full_dataset))),
    test_size=0.2,
    stratify=full_dataset.targets,  # ä¿æŒç±»åˆ«æ¯”ä¾‹ä¸€è‡´
    random_state=42
)

# ä¿®æ­£ï¼šä¸ºè®­ç»ƒå’ŒéªŒè¯åˆ›å»ºç‹¬ç«‹çš„å®ä¾‹ä»¥åº”ç”¨ä¸åŒçš„ Transform
class ApplyTransform(torch.utils.data.Dataset):
    def __init__(self, dataset, indices, transform=None):
        self.dataset = dataset
        self.indices = indices
        self.transform = transform

    def __getitem__(self, index):
        img_path, target = self.dataset.samples[self.indices[index]], self.dataset.targets[self.indices[index]]
        from PIL import Image
        img = Image.open(img_path).convert('RGB')
        if self.transform:
            img = self.transform(img)
        return img, target

    def __len__(self):
        return len(self.indices)

train_loader = DataLoader(ApplyTransform(full_dataset, train_idx, data_transforms['train']),
                          batch_size=batch_size, shuffle=True, num_workers=4)
val_loader = DataLoader(ApplyTransform(full_dataset, val_idx, data_transforms['val']),
                        batch_size=batch_size, shuffle=False, num_workers=4)

# --- 4. æ„å»º ResNet æ¨¡å‹ ---
print(f"æ­£åœ¨åŠ è½½é¢„è®­ç»ƒ ResNet50 å¹¶è¿è¡Œåœ¨: {device}")
model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)

# ä¿®æ”¹æœ€åçš„å…¨è¿æ¥å±‚ä»¥åŒ¹é…ä½ çš„ 5 åˆ†ç±»
num_ftrs = model.fc.in_features
model.fc = nn.Sequential(
    nn.Dropout(0.5),
    nn.Linear(num_ftrs, num_classes)
)
model = model.to(device)

# --- 5. æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨ ---
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)
# 4. å¢åŠ å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.1)
# --- 6. è®­ç»ƒå¾ªç¯ ---
# åˆå§‹åŒ–ç”¨äºè®°å½•ç»˜å›¾æ•°æ®çš„å­—å…¸
history = {
    'train_loss': [], 'train_acc': [],
    'val_loss': [], 'val_acc': []
}

best_val_acc = 0.0
scaler = GradScaler()  # 4090 æ··åˆç²¾åº¦åŠ é€Ÿå™¨

print(f"å¼€å§‹è®­ç»ƒ... è®¾å¤‡: {device}")

patience_counter = 0
early_stop_patience = 10
for epoch in range(num_epochs):
    # --- 1. è®­ç»ƒé˜¶æ®µ ---
    model.train()
    running_loss = 0.0
    corrects = 0
    total_train = 0

    for inputs, labels in tqdm(train_loader, desc=f"Epoch {epoch + 1}/{num_epochs} [Train]"):
        inputs, labels = inputs.to(device), labels.to(device)
        optimizer.zero_grad()

        # 4090 æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
        with autocast(device_type='cuda'):
            outputs = model(inputs)
            loss = criterion(outputs, labels)

        # åå‘ä¼ æ’­ç¼©æ”¾
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        # ç»Ÿè®¡
        running_loss += loss.item() * inputs.size(0)
        _, preds = torch.max(outputs, 1)
        corrects += torch.sum(preds == labels.data)
        total_train += inputs.size(0)

    epoch_train_loss = running_loss / total_train
    epoch_train_acc = corrects.double() / total_train

    # --- 2. éªŒè¯é˜¶æ®µ ---
    model.eval()
    val_loss = 0.0
    val_corrects = 0
    total_val = 0

    with torch.no_grad():
        for inputs, labels in tqdm(val_loader, desc=f"Epoch {epoch + 1}/{num_epochs} [Val]"):
            inputs, labels = inputs.to(device), labels.to(device)

            with autocast(device_type='cuda'):
                outputs = model(inputs)
                v_loss = criterion(outputs, labels)

            val_loss += v_loss.item() * inputs.size(0)
            _, preds = torch.max(outputs, 1)
            val_corrects += torch.sum(preds == labels.data)
            total_val += inputs.size(0)

    epoch_val_loss = val_loss / total_val
    epoch_val_acc = val_corrects.double() / total_val
    scheduler.step(epoch_val_loss)
    # è®°å½•æ•°æ®ç”¨äºç»˜å›¾
    history['train_loss'].append(epoch_train_loss)
    history['train_acc'].append(epoch_train_acc.item())
    history['val_loss'].append(epoch_val_loss)
    history['val_acc'].append(epoch_val_acc.item())

    print(f'Epoch {epoch + 1}: Train Loss: {epoch_train_loss:.4f} Acc: {epoch_train_acc:.4f} | '
          f'Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_acc:.4f}')
    # --- å»ºè®®å¢åŠ ï¼šæ—©åœæœºåˆ¶ (Early Stopping) ---
    # é˜²æ­¢åé¢ 20 ä¸ª epoch éƒ½åœ¨æµªè´¹ç”µå¹¶åŠ å‰§è¿‡æ‹Ÿåˆ
    # --- 3. ä¿å­˜æœ€ä½³æ¨¡å‹ (æ–‡ä»¶åä¸è¦ 0.) ---
    if epoch_val_acc > best_val_acc:
        best_val_acc = epoch_val_acc
        patience_counter = 0  # é‡ç½®è®¡æ•°å™¨

        # æ¸…é™¤æ—§çš„ best æ¨¡å‹ï¼ˆåªåˆ é™¤å‡†ç¡®ç‡ä½äºå½“å‰æœ€ä½³çš„ï¼‰
        for old_file in glob.glob("best_model_acc_face_lstm_*.pth"):
            # ä»æ–‡ä»¶åä¸­æå–å‡†ç¡®ç‡
            try:
                old_acc_str = old_file.split('_')[-1].split('.')[0]
                old_acc = int(old_acc_str) / 10000
                # åªæœ‰å½“æ—§æ¨¡å‹çš„å‡†ç¡®ç‡ä½äºå½“å‰æœ€ä½³å‡†ç¡®ç‡æ—¶æ‰åˆ é™¤
                if old_acc < best_val_acc:
                    os.remove(old_file)
                    print(f"ğŸ”„ åˆ é™¤æ—§æ¨¡å‹: {old_file} (å‡†ç¡®ç‡: {old_acc:.4f})")
            except:
                # å¦‚æœæ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®ï¼Œä¹Ÿåˆ é™¤
                os.remove(old_file)
                print(f"ğŸ”„ åˆ é™¤æ ¼å¼ä¸æ­£ç¡®çš„æ—§æ¨¡å‹: {old_file}")

        # ä¿å­˜æ–°æ¨¡å‹
        acc_suffix = int(best_val_acc * 10000)
        save_path = f'best_model_acc_face_{acc_suffix}.pth'
        torch.save(model.state_dict(), save_path)
        print(f"ğŸŒŸ å‘ç°æ›´ä¼˜æ¨¡å‹: {save_path}")
    else:
        patience_counter += 1
        print(f"âš  éªŒè¯é›†è¡¨ç°æœªæå‡ï¼Œæ—©åœè®¡æ•°å™¨: {patience_counter}/{early_stop_patience}")

        # è§¦å‘æ—©åœ
        if patience_counter >= early_stop_patience:
            print("ğŸ›‘ [Early Stopping] éªŒè¯é›†è¡¨ç°é•¿æœŸåœæ»ï¼Œæå‰ç»“æŸè®­ç»ƒã€‚")
            break

# --- 4. ç»˜åˆ¶å¹¶ä¿å­˜å›¾åƒ ---
plt.figure(figsize=(12, 5))

# ç»˜åˆ¶ Loss å­å›¾
plt.subplot(1, 2, 1)
plt.plot(history['train_loss'], label='Train Loss', color='blue')
plt.plot(history['val_loss'], label='Val Loss', color='red')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training & Validation Loss')
plt.legend()

# ç»˜åˆ¶ Accuracy å­å›¾
plt.subplot(1, 2, 2)
plt.plot(history['train_acc'], label='Train Acc', color='blue')
plt.plot(history['val_acc'], label='Val Acc', color='red')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training & Validation Accuracy')
plt.legend()

plt.tight_layout()
plt.savefig('training_results_face.png')  # ä¿å­˜ä¸ºå›¾ç‰‡æ–‡ä»¶
plt.show()

print(f'è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}')
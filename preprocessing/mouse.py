import cv2
import numpy as np
import time
import math
from pathlib import Path
import json
import csv
from datetime import datetime


# å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨å‰ä¸€å¸§çš„ç°åº¦å›¾ï¼ˆå¸§å·®è·åˆ†æï¼‰
_prev_frame_gray = None

def detect_mouse_pointer(frame, threshold=0.5, min_size=50, max_size=500, template=None):
    """
    åœ¨è§†é¢‘å¸§ä¸­æ£€æµ‹é¼ æ ‡æŒ‡é’ˆ
    
    å‚æ•°:
        frame: è¾“å…¥è§†é¢‘å¸§ (numpyæ•°ç»„)
        threshold: é˜ˆå€¼ï¼Œç”¨äºäºŒå€¼åŒ–å¤„ç† (0-1)
        min_size: é¼ æ ‡æŒ‡é’ˆæœ€å°å¤§å°
        max_size: é¼ æ ‡æŒ‡é’ˆæœ€å¤§å¤§å°
        template: é¼ æ ‡æ¨¡æ¿å›¾åƒ (numpyæ•°ç»„æˆ–åˆ—è¡¨)ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨æ¨¡æ¿åŒ¹é…
    
    è¿”å›:
        tuple: (x, y, radius) é¼ æ ‡æŒ‡é’ˆä½ç½®å’Œå¤§å°ï¼Œå¦‚æœæœªæ£€æµ‹åˆ°è¿”å› None
    """
    global _prev_frame_gray
    
    # å¦‚æœæä¾›äº†æ¨¡æ¿ï¼Œä½¿ç”¨æ¨¡æ¿åŒ¹é…
    if template is not None:
        # å¤„ç†æ¨¡æ¿åˆ—è¡¨ï¼ˆå¤šå¼ æ¨¡æ¿ï¼‰
        if isinstance(template, list):
            for temp in template:
                result = match_mouse_template(frame, temp)
                if result:
                    return result
        else:
            # å•å¼ æ¨¡æ¿
            result = match_mouse_template(frame, template)
            if result:
                return result
    
    # è½¬æ¢ä¸ºç°åº¦å›¾
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    
    # é«˜æ–¯æ¨¡ç³Šå»å™ª
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # æ–¹æ³•0: ä½¿ç”¨å¸§å·®è·åˆ†æï¼ˆé’ˆå¯¹é¼ æ ‡ç§»åŠ¨ï¼‰
    if _prev_frame_gray is not None:
        # è®¡ç®—å½“å‰å¸§ä¸å‰ä¸€å¸§çš„å·®å¼‚
        frame_diff = cv2.absdiff(blurred, _prev_frame_gray)
        
        # å¯¹å·®å¼‚å›¾åƒè¿›è¡Œé˜ˆå€¼å¤„ç†
        _, diff_binary = cv2.threshold(frame_diff, 30, 255, cv2.THRESH_BINARY)
        
        # æŸ¥æ‰¾è½®å»“
        diff_contours, _ = cv2.findContours(diff_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # è¿‡æ»¤è½®å»“ï¼Œå¯»æ‰¾å¯èƒ½çš„é¼ æ ‡ç§»åŠ¨
        for contour in diff_contours:
            area = cv2.contourArea(contour)
            
            # è¿‡æ»¤å¤§å°ï¼ˆé¼ æ ‡ç§»åŠ¨é€šå¸¸æ˜¯å°åŒºåŸŸï¼‰
            if min_size < area < max_size:
                # è®¡ç®—è½®å»“çš„è¾¹ç•Œæ¡†
                x, y, w, h = cv2.boundingRect(contour)
                
                # è®¡ç®—ä¸­å¿ƒç‚¹
                center_x = x + w // 2
                center_y = y + h // 2
                
                # è®¡ç®—åŠå¾„ï¼ˆè¿‘ä¼¼ï¼‰
                radius = int(np.sqrt(area / np.pi))
                
                # æ£€æŸ¥ä¸­å¿ƒç‚¹æ˜¯å¦åœ¨å›¾åƒè¾¹ç¼˜é™„è¿‘
                h_img, w_img = blurred.shape
                edge_margin = 30
                if center_x < edge_margin or center_x > w_img - edge_margin or \
                   center_y < edge_margin or center_y > h_img - edge_margin:
                    continue  # è¾¹ç¼˜åƒç´ ï¼Œè·³è¿‡
                
                # æ£€æŸ¥ç§»åŠ¨åŒºåŸŸçš„å½¢çŠ¶ï¼ˆé¼ æ ‡é€šå¸¸æ˜¯åœ†å½¢æˆ–å°çŸ©å½¢ï¼‰
                aspect_ratio = float(w) / h
                if 0.1 < aspect_ratio < 1.0:  # å…è®¸ä¸€å®šçš„é•¿å®½æ¯”å˜åŒ–
                    # æ›´æ–°å‰ä¸€å¸§
                    _prev_frame_gray = blurred.copy()
                    return center_x, center_y, radius
    
    # æ›´æ–°å‰ä¸€å¸§
    _prev_frame_gray = blurred.copy()
    
    # æ–¹æ³•1: ä½¿ç”¨æ™®é€šé˜ˆå€¼å¤„ç†ï¼ˆé’ˆå¯¹æµ‹è¯•å›¾åƒä¸­çš„ç™½è‰²åœ†å½¢ï¼‰
    _, binary = cv2.threshold(blurred, 127, 255, cv2.THRESH_BINARY)
    
    # æŸ¥æ‰¾è½®å»“
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # è¿‡æ»¤è½®å»“ï¼Œå¯»æ‰¾å¯èƒ½çš„é¼ æ ‡æŒ‡é’ˆ
    for contour in contours:
        area = cv2.contourArea(contour)
        
        # è¿‡æ»¤å¤§å°
        if min_size < area < max_size:
            # è®¡ç®—è½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # è®¡ç®—å®½é«˜æ¯”ï¼ˆé¼ æ ‡æŒ‡é’ˆé€šå¸¸æ¥è¿‘åœ†å½¢ï¼Œå®½é«˜æ¯”æ¥è¿‘1ï¼‰
            aspect_ratio = float(w) / h
            if aspect_ratio < 0.8 or aspect_ratio > 1.2:
                continue  # è·³è¿‡éåœ†å½¢çš„è½®å»“
            
            # è®¡ç®—è½®å»“çš„åœ†å½¢åº¦ï¼ˆåœ†åº¦ï¼‰
            perimeter = cv2.arcLength(contour, True)
            if perimeter > 0:
                circularity = 4 * np.pi * area / (perimeter ** 2)
                # é¼ æ ‡æŒ‡é’ˆé€šå¸¸æ¯”è¾ƒåœ†
                if circularity < 0.7:
                    continue  # è·³è¿‡ä¸åœ†çš„è½®å»“
            
            # è®¡ç®—ä¸­å¿ƒç‚¹
            center_x = x + w // 2
            center_y = y + h // 2
            
            # è®¡ç®—åŠå¾„ï¼ˆè¿‘ä¼¼ï¼‰
            radius = int(np.sqrt(area / np.pi))
            
            # æ£€æŸ¥ä¸­å¿ƒç‚¹æ˜¯å¦åœ¨å›¾åƒè¾¹ç¼˜é™„è¿‘ï¼ˆè¾¹ç¼˜åƒç´ é€šå¸¸ä¸æ˜¯é¼ æ ‡æŒ‡é’ˆï¼‰
            h_img, w_img = blurred.shape
            edge_margin = 30
            if center_x < edge_margin or center_x > w_img - edge_margin or \
               center_y < edge_margin or center_y > h_img - edge_margin:
                continue  # è¾¹ç¼˜åƒç´ ï¼Œè·³è¿‡
            
            return center_x, center_y, radius
    
    # æ–¹æ³•2: ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼å¤„ç†ï¼ˆé’ˆå¯¹çœŸå®åœºæ™¯ï¼‰
    binary2 = cv2.adaptiveThreshold(
        blurred, 255, 
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
        cv2.THRESH_BINARY_INV, 
        11, 2
    )
    
    contours2, _ = cv2.findContours(binary2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    for contour in contours2:
        area = cv2.contourArea(contour)
        if min_size < area < max_size:
            # è®¡ç®—è½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # è®¡ç®—å®½é«˜æ¯”ï¼ˆé¼ æ ‡æŒ‡é’ˆé€šå¸¸æ¥è¿‘åœ†å½¢ï¼Œå®½é«˜æ¯”æ¥è¿‘1ï¼‰
            aspect_ratio = float(w) / h
            if aspect_ratio < 0.8 or aspect_ratio > 1.2:
                continue  # è·³è¿‡éåœ†å½¢çš„è½®å»“
            
            # è®¡ç®—è½®å»“çš„åœ†å½¢åº¦ï¼ˆåœ†åº¦ï¼‰
            perimeter = cv2.arcLength(contour, True)
            if perimeter > 0:
                circularity = 4 * np.pi * area / (perimeter ** 2)
                # é¼ æ ‡æŒ‡é’ˆé€šå¸¸æ¯”è¾ƒåœ†
                if circularity < 0.7:
                    continue  # è·³è¿‡ä¸åœ†çš„è½®å»“
            
            # è®¡ç®—ä¸­å¿ƒç‚¹
            center_x = x + w // 2
            center_y = y + h // 2
            
            # è®¡ç®—åŠå¾„ï¼ˆè¿‘ä¼¼ï¼‰
            radius = int(np.sqrt(area / np.pi))
            
            # æ£€æŸ¥ä¸­å¿ƒç‚¹æ˜¯å¦åœ¨å›¾åƒè¾¹ç¼˜é™„è¿‘ï¼ˆè¾¹ç¼˜åƒç´ é€šå¸¸ä¸æ˜¯é¼ æ ‡æŒ‡é’ˆï¼‰
            h_img, w_img = blurred.shape
            edge_margin = 30
            if center_x < edge_margin or center_x > w_img - edge_margin or \
               center_y < edge_margin or center_y > h_img - edge_margin:
                continue  # è¾¹ç¼˜åƒç´ ï¼Œè·³è¿‡
            
            return center_x, center_y, radius
    
    # æ–¹æ³•3: ç›´æ¥å¯»æ‰¾æœ€äº®çš„åŒºåŸŸï¼ˆé¼ æ ‡æŒ‡é’ˆé€šå¸¸æ¯”è¾ƒäº®ï¼‰
    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(blurred)
    if max_val > 245:  # æ›´é«˜çš„äº®åº¦é˜ˆå€¼ï¼Œå‡å°‘è¯¯æ£€æµ‹
        # ä»¥æœ€äº®ç‚¹ä¸ºä¸­å¿ƒï¼Œæ£€æŸ¥å‘¨å›´åŒºåŸŸçš„äº®åº¦åˆ†å¸ƒ
        center_x, center_y = max_loc
        
        # æ£€æŸ¥ä¸­å¿ƒç‚¹å‘¨å›´çš„åŒºåŸŸæ˜¯å¦çœŸçš„æ˜¯ä¸€ä¸ªå°äº®ç‚¹ï¼ˆé¼ æ ‡æŒ‡é’ˆï¼‰
        # è·å–ä¸­å¿ƒç‚¹å‘¨å›´çš„åŒºåŸŸ
        h, w = blurred.shape
        roi_size = 10
        x_start = max(0, center_x - roi_size)
        x_end = min(w, center_x + roi_size)
        y_start = max(0, center_y - roi_size)
        y_end = min(h, center_y + roi_size)
        
        roi = blurred[y_start:y_end, x_start:x_end]
        
        # è®¡ç®—ROIä¸­çš„å¹³å‡äº®åº¦
        mean_brightness = np.mean(roi)
        
        # è®¡ç®—ROIä¸­é«˜äº®åƒç´ çš„æ•°é‡
        bright_pixels = np.sum(roi > 220)
        total_pixels = roi.size
        bright_ratio = bright_pixels / total_pixels
        
        # é¼ æ ‡æŒ‡é’ˆé€šå¸¸æ˜¯ä¸€ä¸ªå°çš„é«˜äº®åŒºåŸŸï¼Œå‘¨å›´äº®åº¦è¾ƒä½
        # é«˜äº®åƒç´ æ¯”ä¾‹åº”è¯¥é€‚ä¸­ï¼ˆä¸æ˜¯å¤ªå¤§ä¹Ÿä¸æ˜¯å¤ªå°ï¼‰
        if max_val - mean_brightness > 100 and 0.05 < bright_ratio < 0.3:
            # æ£€æŸ¥é«˜äº®åŒºåŸŸæ˜¯å¦é›†ä¸­åœ¨ä¸­å¿ƒ
            # è®¡ç®—ä¸­å¿ƒåŒºåŸŸçš„é«˜äº®åƒç´ æ¯”ä¾‹
            center_roi_size = 5
            cx_start = max(0, center_x - center_roi_size)
            cx_end = min(w, center_x + center_roi_size)
            cy_start = max(0, center_y - center_roi_size)
            cy_end = min(h, center_y + center_roi_size)
            
            center_roi = blurred[cy_start:cy_end, cx_start:cx_end]
            center_bright_pixels = np.sum(center_roi > 220)
            center_total_pixels = center_roi.size
            center_bright_ratio = center_bright_pixels / center_total_pixels
            
            # é¼ æ ‡æŒ‡é’ˆçš„é«˜äº®åŒºåŸŸåº”è¯¥é›†ä¸­åœ¨ä¸­å¿ƒ
            if center_bright_ratio > bright_ratio * 1.5:
                radius = 10  # é»˜è®¤åŠå¾„
                return center_x, center_y, radius
    
    return None


def match_mouse_template(frame, template):
    """
    ä½¿ç”¨æ¨¡æ¿åŒ¹é…åœ¨å¸§ä¸­æŸ¥æ‰¾é¼ æ ‡æŒ‡é’ˆ
    
    å‚æ•°:
        frame: è¾“å…¥è§†é¢‘å¸§ (numpyæ•°ç»„)
        template: é¼ æ ‡æ¨¡æ¿å›¾åƒ (numpyæ•°ç»„)
    
    è¿”å›:
        tuple: (x, y, radius) é¼ æ ‡æŒ‡é’ˆä½ç½®å’Œå¤§å°ï¼Œå¦‚æœæœªæ£€æµ‹åˆ°è¿”å› None
    """
    # è½¬æ¢ä¸ºç°åº¦å›¾
    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)
    
    # è·å–æ¨¡æ¿çš„å°ºå¯¸
    template_height, template_width = template_gray.shape
    
    # æ‰§è¡Œæ¨¡æ¿åŒ¹é…
    result = cv2.matchTemplate(frame_gray, template_gray, cv2.TM_CCOEFF_NORMED)
    
    # æ‰¾åˆ°æœ€ä½³åŒ¹é…ä½ç½®
    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
    
    # è®¾ç½®åŒ¹é…é˜ˆå€¼
    threshold = 0.8
    if max_val >= threshold:
        # è®¡ç®—ä¸­å¿ƒç‚¹
        center_x = max_loc[0] + template_width // 2
        center_y = max_loc[1] + template_height // 2
        radius = int(np.sqrt(template_width * template_height) / 2)
        
        return center_x, center_y, radius
    
    return None


def track_mouse_pointer(video_path, output_path=None, frame_interval=1, show_preview=False, template=None):
    """
    è·Ÿè¸ªè§†é¢‘ä¸­çš„é¼ æ ‡æŒ‡é’ˆè½¨è¿¹
    
    å‚æ•°:
        video_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_path: è¾“å‡ºæ•°æ®è·¯å¾„ï¼Œå¦‚æœä¸º None åˆ™ä¸ä¿å­˜
        frame_interval: å¸§å¤„ç†é—´éš”ï¼Œ1=æ¯å¸§å¤„ç†
        show_preview: æ˜¯å¦æ˜¾ç¤ºå®æ—¶é¢„è§ˆ
        template: é¼ æ ‡æ¨¡æ¿å›¾åƒ (numpyæ•°ç»„)ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨æ¨¡æ¿åŒ¹é…
    
    è¿”å›:
        list: é¼ æ ‡è½¨è¿¹æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« (timestamp, x, y, radius)
    """
    # æ‰“å¼€è§†é¢‘æ–‡ä»¶
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
    
    # è·å–è§†é¢‘ä¿¡æ¯
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"è§†é¢‘ä¿¡æ¯:")
    print(f"  - æ€»å¸§æ•°: {total_frames}")
    print(f"  - FPS: {fps:.2f}")
    print(f"  - åˆ†è¾¨ç‡: {width}x{height}")
    print(f"  - å¸§å¤„ç†é—´éš”: {frame_interval}")
    if template is not None:
        print(f"  - ä½¿ç”¨é¼ æ ‡æ¨¡æ¿è¿›è¡Œæ£€æµ‹")
    
    # åˆå§‹åŒ–é¼ æ ‡è½¨è¿¹æ•°æ®
    mouse_trajectory = []
    processed_frames = 0
    detected_frames = 0
    
    # å¤„ç†è§†é¢‘å¸§
    frame_index = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # è·³è¿‡ä¸éœ€è¦å¤„ç†çš„å¸§
        if frame_index % frame_interval != 0:
            frame_index += 1
            continue
        
        # è®¡ç®—æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
        timestamp = frame_index / fps
        
        # æ£€æµ‹é¼ æ ‡æŒ‡é’ˆ
        mouse_position = detect_mouse_pointer(frame, template=template)
        
        if mouse_position:
            x, y, radius = mouse_position
            mouse_trajectory.append({
                'timestamp': timestamp,
                'x': x,
                'y': y,
                'radius': radius,
                'frame_index': frame_index
            })
            detected_frames += 1
            
            # æ˜¾ç¤ºé¢„è§ˆ
            if show_preview:
                # åœ¨å¸§ä¸Šç»˜åˆ¶é¼ æ ‡æŒ‡é’ˆ
                cv2.circle(frame, (x, y), radius, (0, 0, 255), 2)
                cv2.putText(frame, f"Mouse: ({x}, {y})", (10, 30), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                cv2.putText(frame, f"Frame: {frame_index}/{total_frames}", (10, 60), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
                
                # æ˜¾ç¤ºå¸§
                cv2.imshow('Mouse Tracking', frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
        
        processed_frames += 1
        frame_index += 1
    
    # æ¸…ç†èµ„æº
    cap.release()
    if show_preview:
        cv2.destroyAllWindows()
    
    # ä¿å­˜æ•°æ®
    if output_path:
        save_mouse_data(mouse_trajectory, output_path)
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\nå¤„ç†å®Œæˆ!")
    print(f"  - å¤„ç†å¸§æ•°: {processed_frames}")
    print(f"  - æ£€æµ‹åˆ°é¼ æ ‡å¸§æ•°: {detected_frames}")
    print(f"  - é¼ æ ‡æ£€æµ‹ç‡: {detected_frames/processed_frames*100:.2f}%")
    print(f"  - æ€»è½¨è¿¹ç‚¹: {len(mouse_trajectory)}")
    
    return mouse_trajectory


def process_screen_recording_with_template(video_path, template_paths, output_dir=None, frame_interval=1, show_preview=False):
    """
    ä½¿ç”¨é¼ æ ‡æ¨¡æ¿å¤„ç†å±å¹•å½•åˆ¶è§†é¢‘ï¼Œæå–é¼ æ ‡æ•°æ®
    
    å‚æ•°:
        video_path: è¾“å…¥è§†é¢‘è·¯å¾„
        template_paths: é¼ æ ‡æ¨¡æ¿å›¾åƒè·¯å¾„åˆ—è¡¨ï¼ˆå¯ä»¥æ˜¯å•å¼ æˆ–å¤šå¼ ï¼‰
        output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨è§†é¢‘æ‰€åœ¨ç›®å½•
        frame_interval: å¸§å¤„ç†é—´éš”
        show_preview: æ˜¯å¦æ˜¾ç¤ºé¢„è§ˆ
    
    è¿”å›:
        dict: å¤„ç†ç»“æœ
    """
    # åŠ è½½é¼ æ ‡æ¨¡æ¿å›¾åƒ
    templates = []
    
    # å¤„ç†æ¨¡æ¿è·¯å¾„ï¼ˆæ”¯æŒå•å¼ æˆ–å¤šå¼ ï¼‰
    if isinstance(template_paths, str):
        # å¦‚æœæ˜¯å•å¼ æ¨¡æ¿
        template_paths = [template_paths]
    
    for template_path in template_paths:
        template = cv2.imread(template_path)
        if template is None:
            print(f"è­¦å‘Š: æ— æ³•åŠ è½½é¼ æ ‡æ¨¡æ¿å›¾åƒ: {template_path}")
        else:
            templates.append(template)
            print(f"  - åŠ è½½æ¨¡æ¿: {template_path}")
    
    if not templates:
        raise ValueError(f"æ— æ³•åŠ è½½ä»»ä½•é¼ æ ‡æ¨¡æ¿å›¾åƒ")
    
    video_path = Path(video_path)
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    if output_dir is None:
        output_dir = video_path.parent / 'mouse_data'
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    base_name = f"{video_path.stem}_mouse_template_{timestamp}"
    
    # å¤„ç†è§†é¢‘ï¼Œæå–é¼ æ ‡è½¨è¿¹
    trajectory = track_mouse_pointer(
        video_path=str(video_path),
        output_path=str(output_dir / f"{base_name}.json"),
        frame_interval=frame_interval,
        show_preview=show_preview,
        template=templates
    )
    
    # åˆ†æé¼ æ ‡ç§»åŠ¨
    analysis = analyze_mouse_movement(trajectory)
    
    # ä¿å­˜åˆ†æç»“æœ
    analysis_path = output_dir / f"{base_name}_analysis.json"
    with open(analysis_path, 'w', encoding='utf-8') as f:
        json.dump(analysis, f, indent=2, ensure_ascii=False)
    
    print(f"  - åˆ†æç»“æœå·²ä¿å­˜: {analysis_path}")
    
    # æ‰“å°åˆ†æç»“æœ
    print("\né¼ æ ‡ç§»åŠ¨åˆ†æ:")
    print(f"  - æ€»è½¨è¿¹ç‚¹: {analysis.get('total_points', 0)}")
    print(f"  - æ€»ç§»åŠ¨è·ç¦»: {analysis.get('total_distance', 0):.2f} åƒç´ ")
    print(f"  - å¹³å‡é€Ÿåº¦: {analysis.get('average_speed', 0):.2f} åƒç´ /ç§’")
    print(f"  - æœ€å¤§é€Ÿåº¦: {analysis.get('max_speed', 0):.2f} åƒç´ /ç§’")
    print(f"  - æŒç»­æ—¶é—´: {analysis.get('time_duration', 0):.2f} ç§’")
    
    return {
        'trajectory': trajectory,
        'analysis': analysis,
        'output_dir': str(output_dir)
    }


def save_mouse_data(trajectory, output_path):
    """
    ä¿å­˜é¼ æ ‡è½¨è¿¹æ•°æ®
    
    å‚æ•°:
        trajectory: é¼ æ ‡è½¨è¿¹æ•°æ®åˆ—è¡¨
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    output_path = Path(output_path)
    output_dir = output_path.parent
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©ä¿å­˜æ ¼å¼
    ext = output_path.suffix.lower()
    
    if ext == '.json':
        # ä¿å­˜ä¸º JSON æ ¼å¼
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(trajectory, f, indent=2, ensure_ascii=False)
        print(f"  - æ•°æ®å·²ä¿å­˜ä¸º JSON: {output_path}")
        
    elif ext == '.csv':
        # ä¿å­˜ä¸º CSV æ ¼å¼
        if trajectory:
            with open(output_path, 'w', newline='', encoding='utf-8') as f:
                fieldnames = trajectory[0].keys()
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(trajectory)
            print(f"  - æ•°æ®å·²ä¿å­˜ä¸º CSV: {output_path}")
        
    else:
        # é»˜è®¤ä¿å­˜ä¸º JSON
        json_path = output_path.with_suffix('.json')
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(trajectory, f, indent=2, ensure_ascii=False)
        print(f"  - æ•°æ®å·²ä¿å­˜ä¸º JSON: {json_path}")


def analyze_mouse_movement(trajectory):
    """
    åˆ†æé¼ æ ‡ç§»åŠ¨æ•°æ®
    
    å‚æ•°:
        trajectory: é¼ æ ‡è½¨è¿¹æ•°æ®åˆ—è¡¨
    
    è¿”å›:
        dict: åˆ†æç»“æœ
    """
    if not trajectory:
        return {}
    
    # è®¡ç®—æ€»ç§»åŠ¨è·ç¦»
    total_distance = 0
    speeds = []
    
    for i in range(1, len(trajectory)):
        prev = trajectory[i-1]
        curr = trajectory[i]
        
        # è®¡ç®—è·ç¦»
        distance = np.sqrt((curr['x'] - prev['x'])**2 + (curr['y'] - prev['y'])**2)
        total_distance += distance
        
        # è®¡ç®—æ—¶é—´å·®
        time_diff = curr['timestamp'] - prev['timestamp']
        if time_diff > 0:
            speed = distance / time_diff
            speeds.append(speed)
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    analysis = {
        'total_points': len(trajectory),
        'total_distance': total_distance,
        'average_speed': np.mean(speeds) if speeds else 0,
        'max_speed': max(speeds) if speeds else 0,
        'min_speed': min(speeds) if speeds else 0,
        'time_duration': trajectory[-1]['timestamp'] - trajectory[0]['timestamp'] if len(trajectory) > 1 else 0
    }
    
    return analysis


def process_screen_recording(video_path, output_dir=None, frame_interval=1, show_preview=False):
    """
    å¤„ç†å±å¹•å½•åˆ¶è§†é¢‘ï¼Œæå–é¼ æ ‡æ•°æ®
    
    å‚æ•°:
        video_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨è§†é¢‘æ‰€åœ¨ç›®å½•
        frame_interval: å¸§å¤„ç†é—´éš”
        show_preview: æ˜¯å¦æ˜¾ç¤ºé¢„è§ˆ
    
    è¿”å›:
        dict: å¤„ç†ç»“æœ
    """
    video_path = Path(video_path)
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    if output_dir is None:
        output_dir = video_path.parent / 'mouse_data'
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    base_name = f"{video_path.stem}_mouse_{timestamp}"
    
    # å¤„ç†è§†é¢‘ï¼Œæå–é¼ æ ‡è½¨è¿¹
    trajectory = track_mouse_pointer(
        video_path=str(video_path),
        output_path=str(output_dir / f"{base_name}.json"),
        frame_interval=frame_interval,
        show_preview=show_preview
    )
    
    # åˆ†æé¼ æ ‡ç§»åŠ¨
    analysis = analyze_mouse_movement(trajectory)
    
    # ä¿å­˜åˆ†æç»“æœ
    analysis_path = output_dir / f"{base_name}_analysis.json"
    with open(analysis_path, 'w', encoding='utf-8') as f:
        json.dump(analysis, f, indent=2, ensure_ascii=False)
    
    print(f"  - åˆ†æç»“æœå·²ä¿å­˜: {analysis_path}")
    
    # æ‰“å°åˆ†æç»“æœ
    print("\né¼ æ ‡ç§»åŠ¨åˆ†æ:")
    print(f"  - æ€»è½¨è¿¹ç‚¹: {analysis.get('total_points', 0)}")
    print(f"  - æ€»ç§»åŠ¨è·ç¦»: {analysis.get('total_distance', 0):.2f} åƒç´ ")
    print(f"  - å¹³å‡é€Ÿåº¦: {analysis.get('average_speed', 0):.2f} åƒç´ /ç§’")
    print(f"  - æœ€å¤§é€Ÿåº¦: {analysis.get('max_speed', 0):.2f} åƒç´ /ç§’")
    print(f"  - æŒç»­æ—¶é—´: {analysis.get('time_duration', 0):.2f} ç§’")
    
    return {
        'trajectory': trajectory,
        'analysis': analysis,
        'output_dir': str(output_dir)
    }


def visualize_mouse_trajectory(video_path, trajectory_path, output_video=None, show_preview=False):
    """
    å¯è§†åŒ–é¼ æ ‡è½¨è¿¹
    
    å‚æ•°:
        video_path: åŸå§‹è§†é¢‘è·¯å¾„
        trajectory_path: é¼ æ ‡è½¨è¿¹æ•°æ®è·¯å¾„
        output_video: è¾“å‡ºè§†é¢‘è·¯å¾„
        show_preview: æ˜¯å¦æ˜¾ç¤ºé¢„è§ˆ
    """
    # åŠ è½½é¼ æ ‡è½¨è¿¹æ•°æ®
    with open(trajectory_path, 'r', encoding='utf-8') as f:
        trajectory = json.load(f)
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
    
    # è·å–è§†é¢‘ä¿¡æ¯
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # å‡†å¤‡è¾“å‡ºè§†é¢‘
    output_writer = None
    if output_video:
        output_video = Path(output_video)
        output_video.parent.mkdir(parents=True, exist_ok=True)
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        output_writer = cv2.VideoWriter(str(output_video), fourcc, fps, (width, height))
    
    # å¤„ç†è§†é¢‘å¸§
    frame_index = 0
    trajectory_index = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # ç»˜åˆ¶é¼ æ ‡è½¨è¿¹
        for i in range(trajectory_index, len(trajectory)):
            point = trajectory[i]
            if point['frame_index'] <= frame_index:
                x, y = point['x'], point['y']
                radius = point['radius']
                
                # ç»˜åˆ¶é¼ æ ‡æŒ‡é’ˆ
                cv2.circle(frame, (x, y), radius, (0, 0, 255), 2)
                
                # ç»˜åˆ¶è½¨è¿¹çº¿
                if i > 0:
                    prev_point = trajectory[i-1]
                    if prev_point['frame_index'] == frame_index - 1:
                        prev_x, prev_y = prev_point['x'], prev_point['y']
                        cv2.line(frame, (prev_x, prev_y), (x, y), (0, 255, 0), 2)
                
                trajectory_index = i
            else:
                break
        
        # æ˜¾ç¤ºä¿¡æ¯
        cv2.putText(frame, f"Frame: {frame_index}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(frame, f"Trajectory Points: {trajectory_index}/{len(trajectory)}", (10, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # ä¿å­˜åˆ°è¾“å‡ºè§†é¢‘
        if output_writer:
            output_writer.write(frame)
        
        # æ˜¾ç¤ºé¢„è§ˆ
        if show_preview:
            cv2.imshow('Mouse Trajectory Visualization', frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        frame_index += 1
    
    # æ¸…ç†èµ„æº
    cap.release()
    if output_writer:
        output_writer.release()
    if show_preview:
        cv2.destroyAllWindows()
    
    print(f"  - è½¨è¿¹å¯è§†åŒ–å®Œæˆ")
    if output_video:
        print(f"  - è¾“å‡ºè§†é¢‘å·²ä¿å­˜: {output_video}")


def detect_mouse_in_images(image_paths, template_path=None):
    """
    æ£€æµ‹å¤šå¼ å›¾ç‰‡ä¸­çš„é¼ æ ‡æŒ‡é’ˆ
    
    å‚æ•°:
        image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
        template_path: é¼ æ ‡æ¨¡æ¿å›¾åƒè·¯å¾„æˆ–è·¯å¾„åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    
    è¿”å›:
        dict: æ¯å¼ å›¾ç‰‡çš„é¼ æ ‡æ£€æµ‹ç»“æœ
    """
    results = {}
    
    # å¦‚æœæä¾›äº†æ¨¡æ¿ï¼ŒåŠ è½½æ¨¡æ¿
    templates = []
    
    # å¤„ç†æ¨¡æ¿è·¯å¾„ï¼ˆæ”¯æŒå•å¼ æˆ–å¤šå¼ ï¼‰
    if template_path is not None:
        if isinstance(template_path, str):
            # å•å¼ æ¨¡æ¿
            template_paths = [template_path]
        else:
            # å¤šå¼ æ¨¡æ¿
            template_paths = template_path
        
        for temp_path in template_paths:
            template = cv2.imread(temp_path)
            if template is None:
                print(f"è­¦å‘Š: æ— æ³•åŠ è½½æ¨¡æ¿å›¾åƒ: {temp_path}")
            else:
                templates.append(template)
                print(f"  - åŠ è½½æ¨¡æ¿: {temp_path}")
        
        if templates:
            print(f"å…±åŠ è½½ {len(templates)} å¼ æ¨¡æ¿å›¾åƒ")
    
    for image_path in image_paths:
        print(f"\nå¤„ç†å›¾ç‰‡: {image_path}")
        
        # åŠ è½½å›¾ç‰‡
        image = cv2.imread(image_path)
        if image is None:
            print(f"  âŒ æ— æ³•åŠ è½½å›¾ç‰‡: {image_path}")
            results[image_path] = None
            continue
        
        # æ£€æµ‹é¼ æ ‡
        mouse_position = detect_mouse_pointer(image, template=templates if templates else None)
        
        if mouse_position:
            x, y, radius = mouse_position
            print(f"  âœ… æ£€æµ‹åˆ°é¼ æ ‡æŒ‡é’ˆ:")
            print(f"    ä½ç½®: ({x}, {y})")
            print(f"    åŠå¾„: {radius}")
            
            # åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶é¼ æ ‡æŒ‡é’ˆ
            cv2.circle(image, (x, y), radius, (0, 0, 255), 2)
            cv2.putText(image, f"Mouse: ({x}, {y}) Radius: {radius}", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # ä¿å­˜ç»“æœå›¾ç‰‡
            result_image_path = f"result_{Path(image_path).name}"
            cv2.imwrite(result_image_path, image)
            print(f"  ğŸ“· ç»“æœå·²ä¿å­˜: {result_image_path}")
            
            results[image_path] = {
                'position': (x, y),
                'radius': radius,
                'result_image': result_image_path
            }
        else:
            print(f"  âŒ æœªæ£€æµ‹åˆ°é¼ æ ‡æŒ‡é’ˆ")
            results[image_path] = None
    
    return results


def compare_mouse_positions(results):
    """
    æ¯”è¾ƒå¤šå¼ å›¾ç‰‡ä¸­çš„é¼ æ ‡ä½ç½®
    
    å‚æ•°:
        results: é¼ æ ‡æ£€æµ‹ç»“æœå­—å…¸
    """
    print("\n=== é¼ æ ‡ä½ç½®æ¯”è¾ƒ ===")
    
    # æ”¶é›†æœ‰æ•ˆçš„æ£€æµ‹ç»“æœ
    valid_results = {k: v for k, v in results.items() if v is not None}
    
    if len(valid_results) < 2:
        print("  æ£€æµ‹åˆ°çš„é¼ æ ‡ä½ç½®ä¸è¶³ï¼Œæ— æ³•æ¯”è¾ƒ")
        return
    
    # è®¡ç®—æ‰€æœ‰ä½ç½®ä¹‹é—´çš„è·ç¦»
    image_paths = list(valid_results.keys())
    for i in range(len(image_paths)):
        for j in range(i + 1, len(image_paths)):
            img1 = image_paths[i]
            img2 = image_paths[j]
            
            pos1 = valid_results[img1]['position']
            pos2 = valid_results[img2]['position']
            
            # è®¡ç®—è·ç¦»
            distance = np.sqrt((pos2[0] - pos1[0])**2 + (pos2[1] - pos1[1])**2)
            
            print(f"  {Path(img1).name} â†’ {Path(img2).name}:")
            print(f"    ä½ç½®1: {pos1}")
            print(f"    ä½ç½®2: {pos2}")
            print(f"    è·ç¦»: {distance:.2f} åƒç´ ")


def detect_mouse_by_frame_diff(video_path, output_dir=None, frame_interval=1):
    """
    ä¾æ®å¸§å·®åˆ«æ‰¾åˆ°é¼ æ ‡è½®å»“å¹¶è¾“å‡ºå›¾ç‰‡
    
    å‚æ•°:
        video_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨è§†é¢‘æ‰€åœ¨ç›®å½•
        frame_interval: å¸§å¤„ç†é—´éš”
    
    è¿”å›:
        list: é¼ æ ‡è½®å»“å›¾ç‰‡è·¯å¾„åˆ—è¡¨
    """
    print("=== ä¾æ®å¸§å·®åˆ«æ£€æµ‹é¼ æ ‡è½®å»“ ===")
    
    # æ‰“å¼€è§†é¢‘æ–‡ä»¶
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
    
    # è·å–è§†é¢‘ä¿¡æ¯
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print(f"è§†é¢‘ä¿¡æ¯:")
    print(f"  - æ€»å¸§æ•°: {total_frames}")
    print(f"  - åˆ†è¾¨ç‡: {width}x{height}")
    print(f"  - å¸§å¤„ç†é—´éš”: {frame_interval}")
    
    # è®¾ç½®è¾“å‡ºç›®å½•
    if output_dir is None:
        output_dir = Path(video_path).parent / 'mouse_contours'
    else:
        output_dir = Path(output_dir)
    
    output_dir.mkdir(parents=True, exist_ok=True)
    print(f"  - è¾“å‡ºç›®å½•: {output_dir}")
    
    # åˆå§‹åŒ–å˜é‡
    prev_frame_gray = None
    contour_images = []
    processed_frames = 0
    detected_frames = 0
    
    # é¼ æ ‡ä½ç½®è·Ÿè¸ªï¼ˆç”¨äºè¿åŠ¨è¿ç»­æ€§åˆ†æï¼‰
    prev_mouse_pos = None
    pos_history = []
    
    # å¤„ç†è§†é¢‘å¸§
    frame_index = 0
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # è·³è¿‡ä¸éœ€è¦å¤„ç†çš„å¸§
        if frame_index % frame_interval != 0:
            frame_index += 1
            continue
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # é«˜æ–¯æ¨¡ç³Šå»å™ª
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # å¸§å·®è·åˆ†æ
        if prev_frame_gray is not None:
            # è®¡ç®—å½“å‰å¸§ä¸å‰ä¸€å¸§çš„å·®å¼‚
            frame_diff = cv2.absdiff(blurred, prev_frame_gray)
            
            # å¯¹å·®å¼‚å›¾åƒè¿›è¡Œé˜ˆå€¼å¤„ç†ï¼ˆæé«˜é˜ˆå€¼å‡å°‘è¯¯æ£€æµ‹ï¼‰
            _, diff_binary = cv2.threshold(frame_diff, 40, 255, cv2.THRESH_BINARY)
            
            # å½¢æ€å­¦æ“ä½œï¼Œå»é™¤å™ªå£°
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
            diff_binary = cv2.morphologyEx(diff_binary, cv2.MORPH_OPEN, kernel)
            diff_binary = cv2.morphologyEx(diff_binary, cv2.MORPH_CLOSE, kernel)
            
            # æŸ¥æ‰¾è½®å»“
            contours, _ = cv2.findContours(diff_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # è¿‡æ»¤è½®å»“ï¼Œå¯»æ‰¾å¯èƒ½çš„é¼ æ ‡ç§»åŠ¨
            mouse_contours = []
            for contour in contours:
                area = cv2.contourArea(contour)
                
                # è¿‡æ»¤å¤§å°ï¼ˆæ›´ä¸¥æ ¼çš„èŒƒå›´ï¼‰
                if 0 < area < 300:
                    # è®¡ç®—è½®å»“çš„è¾¹ç•Œæ¡†
                    x, y, w, h = cv2.boundingRect(contour)
                    
                    # æ£€æŸ¥ä¸­å¿ƒç‚¹æ˜¯å¦åœ¨å›¾åƒè¾¹ç¼˜é™„è¿‘
                    edge_margin = 50
                    if x > edge_margin and x + w < width - edge_margin and \
                       y > edge_margin and y + h < height - edge_margin:
                        # æ£€æŸ¥ç§»åŠ¨åŒºåŸŸçš„å½¢çŠ¶ï¼ˆæ›´ä¸¥æ ¼çš„å®½é«˜æ¯”ï¼‰
                        aspect_ratio = float(w) / h
                        if 0.01 < aspect_ratio < 1.5:
                            # æ£€æŸ¥è½®å»“çš„åœ†åº¦
                            perimeter = cv2.arcLength(contour, True)
                            if perimeter > 0:
                                circularity = 4 * math.pi * (area / (perimeter * perimeter))
                                if 0.3 < circularity < 0.9:
                                    mouse_contours.append(contour)
            
            # ä¸ºæ¯ä¸€å¸§ç”Ÿæˆè½®å»“å›¾ç‰‡
            # åˆ›å»ºå½“å‰å¸§çš„å‰¯æœ¬ç”¨äºç»˜åˆ¶
            contour_frame = frame.copy()
            
            # åˆå§‹åŒ–æ£€æµ‹çŠ¶æ€
            detected = False
            detection_info = "æœªæ£€æµ‹åˆ°é¼ æ ‡"
            
            # è¿åŠ¨è¿ç»­æ€§åˆ†æï¼šé€‰æ‹©æœ€å¯èƒ½çš„é¼ æ ‡è½®å»“
            best_contour = None
            best_score = 0
            
            if mouse_contours:
                for contour in mouse_contours:
                    x, y, w, h = cv2.boundingRect(contour)
                    center_x = x + w // 2
                    center_y = y + h // 2
                    current_pos = (center_x, center_y)
                    
                    # è®¡ç®—ä¸ä¹‹å‰ä½ç½®çš„è·ç¦»
                    score = 1.0
                    if prev_mouse_pos:
                        distance = math.sqrt((center_x - prev_mouse_pos[0]) ** 2 + 
                                           (center_y - prev_mouse_pos[1]) ** 2)
                        # é¼ æ ‡ç§»åŠ¨è·ç¦»é€šå¸¸åœ¨åˆç†èŒƒå›´å†…
                        if distance < 200:  # æœ€å¤§ç§»åŠ¨è·ç¦»
                            # è·ç¦»è¶Šè¿‘ï¼Œå¾—åˆ†è¶Šé«˜
                            score += 1.0 / (1.0 + distance / 50)
                    
                    # è½®å»“å¤§å°å¾—åˆ†
                    if 100 < cv2.contourArea(contour) < 250:
                        score += 0.5
                    
                    # å½¢çŠ¶å¾—åˆ†
                    aspect_ratio = float(w) / h
                    if 0.8 < aspect_ratio < 1.2:
                        score += 0.3
                    
                    if score > best_score:
                        best_score = score
                        best_contour = contour
                
                # å¦‚æœæ‰¾åˆ°æœ€ä½³è½®å»“
                if best_contour is not None and best_score > 1.2:  # é˜ˆå€¼ï¼Œç¡®ä¿æœ‰ä¸€å®šå¯ä¿¡åº¦
                    # è®¡ç®—æœ€ä½³è½®å»“çš„ä½ç½®
                    x, y, w, h = cv2.boundingRect(best_contour)
                    center_x = x + w // 2
                    center_y = y + h // 2
                    
                    # æ›´æ–°é¼ æ ‡ä½ç½®å†å²
                    prev_mouse_pos = (center_x, center_y)
                    pos_history.append(prev_mouse_pos)
                    if len(pos_history) > 10:  # ä¿ç•™æœ€è¿‘10ä¸ªä½ç½®
                        pos_history.pop(0)
                    
                    # åœ¨å¸§ä¸Šç»˜åˆ¶è½®å»“
                    cv2.drawContours(contour_frame, [best_contour], -1, (0, 0, 255), 2)
                    
                    # æ›´æ–°æ£€æµ‹ä¿¡æ¯
                    detected = True
                    detection_info = f"æ£€æµ‹åˆ°é¼ æ ‡è½®å»“ (ç½®ä¿¡åº¦: {best_score:.2f})"
                    
                    # æ·»åŠ æ–‡æœ¬ä¿¡æ¯
                    cv2.putText(contour_frame, f"Mouse Contour Detected", 
                               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    cv2.putText(contour_frame, f"Position: ({center_x}, {center_y}) Frame: {frame_index}/{total_frames}", 
                               (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    cv2.putText(contour_frame, f"Confidence: {best_score:.2f}", 
                               (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    
                    # ç»˜åˆ¶å†å²è½¨è¿¹
                    if len(pos_history) > 1:
                        for i in range(1, len(pos_history)):
                            cv2.line(contour_frame, pos_history[i-1], pos_history[i], (0, 255, 255), 2)
                    
                    detected_frames += 1
            
            # ä¸ºæ¯ä¸€å¸§æ·»åŠ åŸºæœ¬ä¿¡æ¯
            cv2.putText(contour_frame, detection_info, 
                       (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            cv2.putText(contour_frame, f"Frame: {frame_index}/{total_frames}", 
                       (10, 190), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # ä¿å­˜è½®å»“å›¾ç‰‡ï¼ˆæ¯ä¸€å¸§éƒ½ä¿å­˜ï¼‰
            output_path = output_dir / f"mouse_contour_frame_{frame_index:06d}.jpg"
            cv2.imwrite(str(output_path), contour_frame)
            contour_images.append(str(output_path))
            
            # æ‰“å°ä¿¡æ¯
            print(f"  ğŸ“· å¸§ {frame_index}: {detection_info}")
        
        # æ›´æ–°å‰ä¸€å¸§
        prev_frame_gray = blurred.copy()
        processed_frames += 1
        frame_index += 1
    
    # æ¸…ç†èµ„æº
    cap.release()
    
    # ç»Ÿè®¡ä¿¡æ¯
    print(f"\nå¤„ç†å®Œæˆ!")
    print(f"  - å¤„ç†å¸§æ•°: {processed_frames}")
    print(f"  - æ£€æµ‹åˆ°é¼ æ ‡è½®å»“å¸§æ•°: {detected_frames}")
    print(f"  - ç”Ÿæˆè½®å»“å›¾ç‰‡: {len(contour_images)}")
    print(f"  - è¾“å‡ºç›®å½•: {output_dir}")
    
    return contour_images


if __name__ == "__main__":
    # é€‰é¡¹1: å¤„ç†è§†é¢‘æ–‡ä»¶ï¼ˆé»˜è®¤æ£€æµ‹æ–¹æ³•ï¼‰
    process_video = False  # æ˜¯å¦å¤„ç†è§†é¢‘
    video_path = r'E:\æ•°æ®\20231229 è®¡ç®—æœºç½‘ç»œè€ƒè¯•æ•°æ®æ±‡æ€»\ç¬¬1ç»„\å½•å±\2021214387_å‘¨å©‰å©·.mp4'  # è¾“å…¥è§†é¢‘è·¯å¾„
    template_paths = [
        r"D:\Pycharm_Projects\demo1_trae\1.png",
        r"D:\Pycharm_Projects\demo1_trae\2.png",
        r"D:\Pycharm_Projects\demo1_trae\5.png",
    ]  # é¼ æ ‡æ¨¡æ¿å›¾åƒè·¯å¾„åˆ—è¡¨ï¼ˆä½¿ç”¨æ¨¡æ¿åŒ¹é…ï¼‰
    output_dir = None  # è¾“å‡ºç›®å½•
    frame_interval = 1  # å¸§å¤„ç†é—´éš”
    show_preview = True  # æ˜¯å¦æ˜¾ç¤ºé¢„è§ˆ
    visualize = True  # æ˜¯å¦ç”Ÿæˆå¯è§†åŒ–è§†é¢‘
    
    # é€‰é¡¹2: ä¾æ®å¸§å·®åˆ«æ£€æµ‹é¼ æ ‡è½®å»“
    process_frame_diff = True  # æ˜¯å¦ä½¿ç”¨å¸§å·®è·åˆ†æ
    frame_diff_output_dir =r"D:\Pycharm_Projects\demo1_trae\output\diff"   # å¸§å·®è·åˆ†æè¾“å‡ºç›®å½•
    frame_diff_interval = 1  # å¸§å·®è·åˆ†æå¤„ç†é—´éš”
    
    # é€‰é¡¹3: å¤„ç†å¤šå¼ å›¾ç‰‡
    process_images = False  # æ˜¯å¦å¤„ç†å›¾ç‰‡
    image_paths = [
        r"D:\Pycharm_Projects\demo1_trae\3.png",
         r"D:\Pycharm_Projects\demo1_trae\4.png"
    ]
    image_template_path = None  # å›¾ç‰‡æ£€æµ‹ä½¿ç”¨çš„æ¨¡æ¿
    
    # å¤„ç†è§†é¢‘
    if process_video:
        print("=== å¤„ç†è§†é¢‘æ–‡ä»¶ ===")
        if template_paths:
            # ä½¿ç”¨æ¨¡æ¿åŒ¹é…
            result = process_screen_recording_with_template(
                video_path=video_path,
                template_paths=template_paths,
                output_dir=output_dir,
                frame_interval=frame_interval,
                show_preview=show_preview
            )
        else:
            # ä½¿ç”¨é»˜è®¤æ£€æµ‹æ–¹æ³•
            result = process_screen_recording(
                video_path=video_path,
                output_dir=output_dir,
                frame_interval=frame_interval,
                show_preview=show_preview
            )
        
        # å¦‚æœéœ€è¦å¯è§†åŒ–
        if visualize:
            from pathlib import Path
            video_path_obj = Path(video_path)
            output_dir_obj = Path(result['output_dir'])
            
            # æŸ¥æ‰¾è½¨è¿¹æ–‡ä»¶
            if template_paths:
                trajectory_files = list(output_dir_obj.glob(f"{video_path_obj.stem}_mouse_template_*.json"))
            else:
                trajectory_files = list(output_dir_obj.glob(f"{video_path_obj.stem}_mouse_*.json"))
            
            if trajectory_files:
                trajectory_path = trajectory_files[0]
                output_video = output_dir_obj / f"{video_path_obj.stem}_visualization.mp4"
                
                visualize_mouse_trajectory(
                    video_path=video_path,
                    trajectory_path=str(trajectory_path),
                    output_video=str(output_video),
                    show_preview=show_preview
                )

    # ä¾æ®å¸§å·®åˆ«æ£€æµ‹é¼ æ ‡è½®å»“
    if process_frame_diff:
        print("\n=== ä¾æ®å¸§å·®åˆ«æ£€æµ‹é¼ æ ‡è½®å»“ ===")
        # è°ƒç”¨å¸§å·®è·åˆ†æå‡½æ•°
        contour_images = detect_mouse_by_frame_diff(
            video_path=video_path,
            output_dir=frame_diff_output_dir,
            frame_interval=frame_diff_interval
        )
        
        print(f"\n=== å¸§å·®è·åˆ†æå®Œæˆ ===")
        print(f"  - ç”Ÿæˆè½®å»“å›¾ç‰‡: {len(contour_images)}")
        if contour_images:
            print(f"  - ç¤ºä¾‹è¾“å‡º: {contour_images[0]}")

    # å¤„ç†å›¾ç‰‡
    if process_images:
        print("\n=== å¤„ç†å›¾ç‰‡æ–‡ä»¶ ===")
        # æ£€æµ‹å›¾ç‰‡ä¸­çš„é¼ æ ‡
        image_results = detect_mouse_in_images(image_paths, template_path=image_template_path)
        
        # æ¯”è¾ƒé¼ æ ‡ä½ç½®
        compare_mouse_positions(image_results)
        
